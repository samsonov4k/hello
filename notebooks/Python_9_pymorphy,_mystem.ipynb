{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsonov4k/hello/blob/main/notebooks/Python_9_pymorphy%2C_mystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лемматизация, морф.анализ\n",
        "\n",
        "Важно!\n",
        "\n",
        "Для установки на домашний компьютер самый простой вариант - **pymorphy3**\n",
        "\n",
        "**pymystem3** уже лет 10 не могут адаптировать для Windows: он работает, но слишком медленно\n",
        "\n",
        "Мы также воспользуемся **spaCy** - там отличные языковые модельки, большой выбор языков, но spaCy всегда отстает от обновлений Python"
      ],
      "metadata": {
        "id": "zkU-qYW1fIif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3\n",
        "!pip install pymystem3\n",
        "# для VS Code - через %"
      ],
      "metadata": {
        "id": "EvWQK_ehdeJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# все импорты...\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "# from nltk import download # для Colab\n",
        "# download('punkt_tab')\n",
        "# download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('russian')\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import pymorphy3\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()\n",
        "\n",
        "from pymystem3 import Mystem\n",
        "mystem = Mystem()"
      ],
      "metadata": {
        "id": "CBDuVgv9dHRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для русского основых лемматизатора два: Pymorphy и Mystem."
      ],
      "metadata": {
        "id": "FgQl8UrFi42Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyMorphy3 (2)\n",
        "\n",
        "Очень популярный и простой инструмент для лемматизации русского языка"
      ],
      "metadata": {
        "id": "AnSyiricjK2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pymorphy3"
      ],
      "metadata": {
        "id": "FKfugkd7jKo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pymorphy3 import MorphAnalyzer\n",
        "# morph = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "Bgp0f43Uj_0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### основная функция - parse()\n",
        "     \n",
        "Она будет похожа на analyze в mystem, возвращает список объектов Parse\n",
        "\n",
        "Первый в списке - самый вероятный разбор (у каждого есть score)\n",
        "\n",
        "Грамматическая информация хранится в объекте OpencorporaTag и из него удобно доставать"
      ],
      "metadata": {
        "id": "KM_gsv_UoFTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('человек')"
      ],
      "metadata": {
        "id": "pZCMXQ_FkCTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Документация [здесь](https://pymorphy2.readthedocs.io/en/stable/user/guide.html#id3), обозначения для граммем [здесь](https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html#grammeme-docs)"
      ],
      "metadata": {
        "id": "wamXCo5DkcBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# сделаем красиво\n",
        "print('Cлово - ', morph.parse('человеком')[0].word)\n",
        "print('Лемма слова - ', morph.parse('человеком')[0].normal_form)\n",
        "print('Грамматическая информация слова - ', morph.parse('человеком')[0].tag)\n",
        "print('Часть речи слова - ', morph.parse('человеком')[0].tag.POS)\n",
        "print('Род слова - ', morph.parse('человеком')[0].tag.gender)\n",
        "print('Число слова - ', morph.parse('человеком')[0].tag.number)\n",
        "print('Падеж слова - ', morph.parse('человеком')[0].tag.case)"
      ],
      "metadata": {
        "id": "NEuYI00MpGZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# для лемматизации нужна именно эта команда\n",
        "morph.parse('человеком')[0].normal_form"
      ],
      "metadata": {
        "id": "ynZpWFdAkbdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте возьмем Сэлинджера..."
      ],
      "metadata": {
        "id": "REuAGiOqiJuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Увы! pymorphy не умеет токенизировать, поэтому..."
      ],
      "metadata": {
        "id": "zGbDbO1QmaUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# препроцессинг в 1 функцию (старая функция)\n",
        "def clean_text(text):\n",
        "  text_list_nltk = word_tokenize(text.lower()) # токенизация\n",
        "  text_clean = [word for word in text_list_nltk if word not in stop_words and word[0].isalpha()] # чистим от стоп-слов и пунктуации\n",
        "  return text_clean\n",
        "\n",
        "with open('bananafish.txt', 'r', encoding='utf-8') as file:\n",
        "  bananafish = file.read()\n",
        "bananafish_tokens = clean_text(bananafish)\n",
        "bananafish_tokens"
      ],
      "metadata": {
        "id": "PGjw9On5mTNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_lemmatized = []\n",
        "for word in bananafish_tokens:\n",
        "    result = morph.parse(word)\n",
        "    most_probable_result = result[0] ## почему мы берем первый разбор? см.в этом месте: https://pymorphy2.readthedocs.io/en/latest/user/guide.html#select-correct\n",
        "    normal_form = most_probable_result.normal_form\n",
        "    words_lemmatized.append(normal_form)\n",
        "\n",
        "    # или покороче, все в одну строку:\n",
        "    # words_lemmatized.append(morph.parse(word)[0].normal_form)\n",
        "\n",
        "words_lemmatized"
      ],
      "metadata": {
        "id": "QESmsCy7ZEkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(words_lemmatized).most_common(10)"
      ],
      "metadata": {
        "id": "Pw2iCYe_qW-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "freq_bigramms = Counter(nltk.bigrams(words_lemmatized))\n",
        "freq_bigramms.most_common(10)"
      ],
      "metadata": {
        "id": "b1mL5YY9mTHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание\n",
        "\n",
        "Соберите лемматизацию pymorphy в одну функцию"
      ],
      "metadata": {
        "id": "JFeUJlpBu-LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemm_pymorphy(text):\n",
        "  text_list_nltk = word_tokenize(text.lower()) # токенизация\n",
        "  text_clean = [word for word in text_list_nltk if word not in stop_words and word[0].isalpha()] # чистим от стоп-слов и пунктуации\n",
        "  # ваш код\n",
        "  return\n",
        "\n",
        "# проверьте ее\n",
        "lemm_pymorphy(bananafish)[:10] # посмотрим на первые 10 лемм"
      ],
      "metadata": {
        "id": "vaZeB-q3u9Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лемматизатор MyStem"
      ],
      "metadata": {
        "id": "x8EP6EpwrJga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравнительная точность pymorphy и mystem для русского языка [здесь](http://web-corpora.net/wsgi/mystemplus.wsgi/mystemplus/compare_table/)\n"
      ],
      "metadata": {
        "id": "ZEOdXo04rQ12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pymystem3"
      ],
      "metadata": {
        "id": "cubFjRCARmhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pymystem3 import Mystem\n",
        "# mystem = Mystem()"
      ],
      "metadata": {
        "id": "Ia7eFtB2T2Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mystem.lemmatize('mystem даже сам! Умеет токенизировать текст')"
      ],
      "metadata": {
        "id": "q-3BA2pYR4xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_lemmatized_mystem = mystem.lemmatize(bananafish)\n",
        "words_lemmatized_mystem"
      ],
      "metadata": {
        "id": "81ocRK_Li4Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(words_lemmatized_mystem).most_common(10)"
      ],
      "metadata": {
        "id": "7aHw06NKViEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание"
      ],
      "metadata": {
        "id": "pKPHZm1Bvf_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# что-то пошло не так, как поправить?\n",
        "# исправьте код с помощью цикла for + if так, чтобы отсеять пунктуацию\n",
        "\n",
        "result = []\n",
        "for i in # продолжите программу\n",
        "  if"
      ],
      "metadata": {
        "id": "Es9N1mEFasgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# снова найдите частотные слова\n",
        "Counter(result).most_common(10)"
      ],
      "metadata": {
        "id": "bqTiY2wA4PU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "А теперь снова соберем лемматизацию от MyStem в одну функцию (помните, что токенизация не нужна - MyStem токенизирует сам):"
      ],
      "metadata": {
        "id": "Xq_St47rv8LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemm_mystem(text):\n",
        "\n",
        "\n",
        "# проверьте ее\n",
        "lemm_mystem(bananafish)[:10] # посмотрим на первые 10 лемм"
      ],
      "metadata": {
        "id": "sZXhTju7wDc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### морф. анализ в MyStem"
      ],
      "metadata": {
        "id": "GIhezJeRV7Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sometext = \"Задача NLI важна для компьютерных лингвистов\"\n",
        "analyzed = mystem.analyze(sometext)\n",
        "print(analyzed)"
      ],
      "metadata": {
        "id": "Njf3K2AmV-9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# возвращает список словарей\n",
        "# каждый словарь имеет либо одно поле 'text' (когда попался пробел) или text и analysis\n",
        "# в analysis снова список словарей с вариантами разбора (первый самый вероятный)\n",
        "# wt - вес, увереность в правильности\n",
        "# 'gr' - грамматическая информация, 'lex' - лемма\n",
        "# analysis - может быть пустым списком\n",
        "\n",
        "print('Слово - ', analyzed[0]['text'])\n",
        "print('Разбор слова - ', analyzed[0]['analysis'][0])\n",
        "print('Лемма слова - ', analyzed[0]['analysis'][0]['lex'])\n",
        "print('Грамматическая информация слова - ', analyzed[0]['analysis'][0]['gr'])"
      ],
      "metadata": {
        "id": "E_yHl1NMWsFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in mystem.analyze(sometext):\n",
        "  if word.get('analysis'):\n",
        "    print(word['analysis'][0]['lex'])\n",
        "\n",
        "# [word['analysis'][0]['lex'] for word in mystem.analyze(sometext) if word.get('analysis')]"
      ],
      "metadata": {
        "id": "N34ltOYdtbuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Библиотека spaCy\n",
        "\n",
        "У нее отличный набор языков! Позже вы еще будете использовать ее для синтаксиса (на компьютерной лингвистике)\n",
        "\n",
        "Тем не менее, русский язык лучше лемматизировать специальными библиотеками для него! Результат у spaCy будет хуже\n",
        "\n",
        "Установка [здесь](https://spacy.io/usage/models#quickstart) (в том числе, для разных языков)"
      ],
      "metadata": {
        "id": "I6PbA-M_voL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm\n",
        "import spacy\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "import ru_core_news_sm\n",
        "nlp = ru_core_news_sm.load()"
      ],
      "metadata": {
        "id": "cfkSLof5vzbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Документация лемматизатора [здесь](https://spacy.io/api/lemmatizer)\n",
        "\n",
        "Морф. анализ [здесь](https://spacy.io/api/morphologizer)"
      ],
      "metadata": {
        "id": "Tqr86WnYILrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# передаем текст в модель spaCy\n",
        "doc = nlp(\"Здесь пример текста на русском\")"
      ],
      "metadata": {
        "id": "LcOoJSFzvzZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in doc:\n",
        "  print('Слово -', w.text)\n",
        "  print('Часть речи -', w.pos_)\n",
        "  print('Разбор слова -', w.morph)\n",
        "  print('Лемма -', w.lemma_)\n",
        "  print()"
      ],
      "metadata": {
        "id": "tZueWiO5vzEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_lemmatized_spacy = []\n",
        "doc = nlp(bananafish.lower())\n",
        "for word in doc:\n",
        "  lem = word.lemma_\n",
        "  if lem not in stop_words and lem[0].isalpha():\n",
        "    words_lemmatized_spacy.append(lem)\n",
        "\n",
        "Counter(words_lemmatized_spacy).most_common(10)"
      ],
      "metadata": {
        "id": "PFvAgsqvvzW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберем лемматизацию spaCy в одну функцию"
      ],
      "metadata": {
        "id": "jS9JwoTHwRIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemm_spacy(text):\n",
        "\n",
        "\n",
        "# проверьте ее\n",
        "lemm_spacy(bananafish)[:10] # посмотрим на первые 10 лемм"
      ],
      "metadata": {
        "id": "dAm8da7yv1xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ответы для всех функций, которые мы собирали выше :"
      ],
      "metadata": {
        "id": "rekKBqjhwPAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "def lemm_pymorphy(text):\n",
        "  text_list_nltk = word_tokenize(text.lower())\n",
        "  text_clean = [word for word in text_list_nltk if word not in stop_words and word[0].isalpha()]\n",
        "  lemm = [morph.parse(word)[0].normal_form for word in text_clean]\n",
        "  return lemm\n",
        "\n",
        "def lemm_mystem(text):\n",
        "  lemm = mystem.lemmatize(text)\n",
        "  lemm_clean = [word for word in lemm if word not in stop_words and word[0].isalpha()]\n",
        "  return lemm_clean\n",
        "\n",
        "def lemm_spacy(text):\n",
        "  doc = nlp(text.lower())\n",
        "  lem_list = [word.lemma_ for word in doc if word.lemma_ not in stop_words and word.lemma_[0].isalpha()]\n",
        "  return lem_list"
      ],
      "metadata": {
        "id": "Ub9AJd9fwS4k",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2"
      ],
      "metadata": {
        "id": "2PCXI-BLk-_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Омонимия"
      ],
      "metadata": {
        "id": "iW0EfWL7dVk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# омонимия\n",
        "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
        "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
      ],
      "metadata": {
        "id": "G1rOZvZz314U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "перед вами два предложения с омонимами: лемматизируйте их через pymorphy, mystem, spaCy"
      ],
      "metadata": {
        "id": "83qMZ3a1rCMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pymorphy\n"
      ],
      "metadata": {
        "id": "kuauofnG4BMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mystem\n"
      ],
      "metadata": {
        "id": "xXqRRXli4BAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spaCy\n"
      ],
      "metadata": {
        "id": "nXGsQyxXv3-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "лемматизируйте через pymorphy, mystem, spaCy"
      ],
      "metadata": {
        "id": "k4xd0nAnrFbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Гуляя в мужской парке по парку им.Карима Тинчурина в Казане, я увидел много белок. Я кармил их куриными яичками, но они не ели белок.'"
      ],
      "metadata": {
        "id": "c_T1tV9ndIta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pymorphy\n"
      ],
      "metadata": {
        "id": "z_MIgDX9ck56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mystem\n"
      ],
      "metadata": {
        "id": "vRnqfQ9OclWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spaCy\n"
      ],
      "metadata": {
        "id": "CljxI-r9OvVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Варкалось. Хливкие шорьки\n",
        "Пырялись по наве,\n",
        "И хрюкотали зелюки,\n",
        "Как мюмзики в мове.\n",
        "\n",
        "О, бойся Бармаглота, сын!\n",
        "Он так свирлеп и дик!\n",
        "А в глу́ше ры́мит исполин —\n",
        "Злопастный Брандашмыг!\n",
        "\n",
        "Но взял он меч, и взял он щит,\n",
        "Высоких полон дум.\n",
        "В глущобу путь его лежит\n",
        "Под дерево Тумтум.\n",
        "\n",
        "Он стал под дерево и ждёт.\n",
        "И вдруг граахнул гром —\n",
        "Летит ужасный Бармаглот\n",
        "И пылкает огнём!\n",
        "\n",
        "Раз-два, раз-два! Горит трава,\n",
        "Взы-взы — стрижает меч,\n",
        "Ува! Ува! И голова\n",
        "Барабардает с плеч!\n",
        "\n",
        "О светозарный мальчик мой!\n",
        "Ты победил в бою!\n",
        "О храброславленный герой,\n",
        "Хвалу тебе пою!\n",
        "\n",
        "Варкалось. Хливкие шорьки\n",
        "Пырялись по наве.\n",
        "И хрюкотали зелюки,\n",
        "Как мюмзики в мове.'''"
      ],
      "metadata": {
        "id": "Y5GwKg_qceVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pymorhy\n"
      ],
      "metadata": {
        "id": "qK1EP7_4cq--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mystem\n"
      ],
      "metadata": {
        "id": "0VCYxACzctu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spaCy\n"
      ],
      "metadata": {
        "id": "lsHbDPZjwAgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Существуют и другие библиотеки для лемматизации\n",
        "\n",
        "русский язык:\n",
        "\n",
        "- [RNNmorph](https://github.com/IlyaGusev/rnnmorph)\n",
        "- [deeppavlov](http://docs.deeppavlov.ai/en/master/)\n",
        "\n",
        "другие языки:\n",
        "- [UralicNLP](https://github.com/mikahama/uralicNLP)\n",
        "- [hfst от Apertium](https://wiki.apertium.org/wiki/Hfst)\n",
        "- [Stanza](https://stanfordnlp.github.io/stanza/)\n",
        "- [Trankit](https://trankit.readthedocs.io/en/latest/posdep.html)"
      ],
      "metadata": {
        "id": "-EkDinB6d9HH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Маленькое доп. задание для тех, кто плохо разобрался\n",
        "\n",
        "Предобработайте текст, который находится в переменной text, выполнив следующие этапы:\n",
        "\n",
        "* Токенизация\n",
        "* Приведение к нижнему регистру\n",
        "* Удаление пунктуации\n",
        "* Удаление стоп-слов\n",
        "* Лемматизация\n",
        "\n",
        "Многие действия вы умеете выполнять разными способами, выполните эти шаги так, как удобно вам\n",
        "\n",
        "В конце у вас должен получиться список, содержащий слова из текста, в удобном для дальнейшей работы формате.\n",
        "\n"
      ],
      "metadata": {
        "id": "9b8-W_eK4z7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"По результатам оценки критериев вузам присвоили один из рейтинговых статусов. Высшая школа экономики вошла в лидерскую группу А+, заняв первое место по таким критериям, как «Востребованность выпускников в найме», «Качество образовательной среды» и «Активность по развитию школьного образования».\n",
        "Презентация рейтинга прошла в Москве на международной конференции AI Journey 2023. Один из основных критериев оценки вузов при расчете рейтинга — размер заработной платы молодых специалистов в течение года после завершения обучения (при трудоустройстве по специальности). В вузах-лидерах рейтинга средняя зарплата выпускников составила около 140 тыс. рублей.\n",
        "В НИУ ВШЭ с 2021 года действует Центр искусственного интеллекта. Миссия Центра развитие и внедрение технологий искусственного интеллекта в разные сферы жизни человека и общества, отрасли науки и сектора экономики. НИУ ВШЭ стал одним из победителей конкурса на получение гранта от Правительства Российской Федерации для создания центра искусственного интеллекта.\n",
        "Конкурс проводился в рамках федерального проекта «Искусственный интеллект», основная задача которого — стимулирование развития и внедрения технологий ИИ в России.\n",
        "«По поручению главы государства Альянс в сфере ИИ совместно с Минобрнауки разработали рейтинг российских вузов по качеству подготовки специалистов по ИИ. Рейтинг является важнейшим индикатором качества образования в области ИИ и наглядно отражает мнение работодателей о том, насколько образовательные программы актуальны и отвечают запросу рынка. Среди 180 вузов, оказавшихся в рейтинге, 10 имеют оценки А+, А (хорошее качество) B+, B (приемлемое качество).\n",
        "Абсолютные лидеры — это ВШЭ, МФТИ и ИТМО. Таким образом, ТОП-10 российских университетов уже могут конкурировать за звание лучших, а значит готовят высококвалифицированных специалистов и успешно развивают науку в области искусственного интеллекта», — отметил Дмитрий Чернышенко, заместитель председателя Правительства России, куратор нацпрограммы «Цифровая экономика».\n",
        "Для объективной оценки качества специалистов по ИИ эксперты выделили 13 критериев, включая такие аспекты, как уровень заработных плат выпускников, их востребованность на рынке труда, наличие научных публикаций на конференциях и в журналах, количество призеров студенческих олимпиад, средний балл по ЕГЭ, и наличие программ, прошедших профессионально-общественную аккредитацию со стороны Альянса.\"\"\""
      ],
      "metadata": {
        "id": "Y8C9eNhR4zYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Приведение к нижнему регистру\n"
      ],
      "metadata": {
        "id": "WJqd05LF5IHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Токенизация\n"
      ],
      "metadata": {
        "id": "8mwOt4_o5GLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление пунктуации\n"
      ],
      "metadata": {
        "id": "5sN71auh5JUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление стоп-слов\n"
      ],
      "metadata": {
        "id": "bupVxNrO5KwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Лемматизация\n"
      ],
      "metadata": {
        "id": "sLV-iVH15MAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Теперь можете еще раз собрать результат в функцию\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tISDqSVO5Np5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}